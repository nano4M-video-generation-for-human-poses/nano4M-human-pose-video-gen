# Data-Loader Suite

This directory wraps every flavour of the **Penn-Action** dataset we use across the Mâ€‘series models.

```
â”œâ”€â”€ create_penn_action_masked_dataloader.py        # baseline factory
â”œâ”€â”€ create_penn_action_masked_dataloader_opt.py    # optimised factory
â”œâ”€â”€ M1/                                            # â‡¢ loader for M1
â”œâ”€â”€ M4/                                            # â‡¢  loader for M4
â”œâ”€â”€ M3/                                            # â‡¢ loader for M3
â””â”€â”€ M2/                                            # â‡¢ loader for M2
```

---

## 1 â†—ï¸Ž `create_penn_action_masked_dataloader.py`
A **dropâ€‘in utility** that turns any split (train/eval/test) into a masked, batched PyTorch iterator.

**Pipeline**
1. Composes a `SimpleMultimodalMasking` transform to inject `[MASK]` tokens.
2. Instantiates `PennActionMultimodalDataset` â€“ one fileâ€‘perâ€‘frame layout.
3. Adds a `DistributedSampler` when `distributed=True`.
4. Returns a vanilla `torch.utils.data.DataLoader`.

---

## 2 ðŸš€ `create_penn_action_masked_dataloader_opt.py`
A **performanceâ€‘oriented** variant with multiple qualityâ€‘ofâ€‘life tweaks:

| Feature | Why it matters |
|---------|----------------|
| **DataLoader2 backend (optâ€‘in)** | Better IO overlap & fault tolerance under distributed training. |
| **`prefetch_factor`, `persistent_workers`** | Keeps worker pools warm, reducing epochâ€‘toâ€‘epoch stalls. |
| **Optional CUDA preâ€‘fetch** | Asynchronously moves the *next* batch to GPU, hiding hostâ†’device latency. |
| **Infinite iterator wrapper** | Supports streamerâ€‘style training loops that never reset epoch counters. |

---

## 3 Modelâ€‘specific folders (M1, M2, M3, M4)
Each subâ€‘directory contains a thin adapter that *only* tweaks path conventions and modality lists so the shared factories above work with that modelâ€™s preprocessing scheme.

---
